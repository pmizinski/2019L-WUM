---
title: PD6
author: Bogdan Jastrzębski
date: "30 kwietnia 2019"
output: 
  html_document:
    toc: true
    number_sections: true
    toc_float: true
    theme: "paper"
---

# Wstęp 

W tej pracy rozpatrzymy problem oceny jakości klasteryzacji. W przypadku wielowymiarowych danych nie możemy ocenić "na oko", czy klasteryzacja przebiegła pomyślnie. By to zrobić musimy obliczyć pewne statystyki dla podzielonych danych.

W tej pracy przyjrzę się następującym statystykom zewnętrznym:

- indeksowi Randa

- indeksowi Jaccarda

- indeksowi Fowlkesa-Mallowsa

i wewnętrznym:

- gammie

- indeksowi Daviesa-Bouldin

- indeksowi Dunna

Wymienione statystyki przetestuję na zbiorze danych "shapes", dla algorytmów "kmeans" i "hclust2" oraz różnych zadanych liczb klastrów.

```{r, echo = FALSE}
load('statPlots.rda')
load('etykiety.rda')
load('data.rda')
library(ggplot2)
library(gridExtra)
```

## Dane

Oto jak przedstawiają się zbiory testowe:

```{r, echo = FALSE}
plot(shapePlot)
```

Jak widać są bardzo różnorodne. W dalszej części układ 
wykresów będzie odpowiadał powyższemu układowi.

# Statystyki zewnętrzne

## Indeks Randa

Indeks Randa przyjmuje wartości z przedziału $[0,1]$ i 
jest miarą podobieństwa między klastrami. Podział o najwyższym indeksie Randa jest potencjalnie najlepszy.

Oto jak przedstawiają się wartości indeksu Randa dla 
różnych zbiorów (układ odpowiada układowi w części wyżej) i
algorytmów klasteryzacji kmeans (zaznaczone na niebiesko) i hclust2 (zaznaczone na czerwono).

```{r, echo = FALSE}
plot(randPlot)
```

Jak widać indeks randa umiarkowanie dobrze przewiduje liczbę podzbiorów zbiorów testowych. Szczególnie ciekawym wydaje się wykres w prawym górnym rogu, ponieważ kmeans i hclust2 osiągnęły zupełnie różne wyniki, co więcej hclust2 osiągnął wynik idealny.

```{r, echo = FALSE}
  
kplot <-ggplot(d4, aes(x = x, y = y, color = as.factor(l4_k[[3]]))) +
          geom_point() + 
          theme_bw() + 
          theme(legend.position = 'none',
                axis.title = element_blank(),
                axis.text = element_blank(),
                axis.ticks = element_blank()) + 
          ggtitle('kmeans')
hplot <-ggplot(d4, aes(x = x, y = y, color = as.factor(l4_h[[3]]))) +
          geom_point() + 
          theme_bw() + 
          theme(legend.position = 'none',
                axis.title = element_blank(),
                axis.text = element_blank(),
                axis.ticks = element_blank()) + 
          ggtitle("hclust2")

grid.arrange(kplot, hplot, ncol=2)
```

Jak widać hclust2 rzeczywiście poradził sobie bardzo dobrze, podczas gdy kmeans nie dało dobrego wyniku.


## Indeks Jaccarda

Podobnie jak indeks Randa, indeks Jaccarda mierzy podobieństwo między zbiorami i zwraca wartości z przedziału $[0,1]$, im wyższe tym lepiej.

Oto jak przedstawiają się wartości indeksu Jaccarda dla 
różnych zbiorów, wartości k i
algorytmów klasteryzacji kmeans (zaznaczone na niebiesko) i hclust2 (zaznaczone na czerwono).

```{r, echo = FALSE}
plot(jaccPlot)
```

Tutaj ponownie indeks Jaccarda przewiduje dość dobrze optymalną liczbę k, w szczególności działa moim zdaniem lepiej na zbiorze trzecim od lewej w górnym wierszu (porównaj z tym samym wykresem indeksu Randa) i dolnym po prawej, gdzie jasno wyznacza dobre k, podczas gdy indeks Randa był już wysoki dla niższych wartości k.


## Indeks Fowlkesa-Mallowsa

Wartości z przedziału $[0,1]$ i argument maksimum odpowiada potencjalnie najlepszemu k. 

Oto jak przedstawiają się wartości indeksu Fowlkesa-Mallowsa dla 
naszych zbiorów, różnych k i algorytmów kmeans i hclust2.

```{r, echo = FALSE}
plot(folkPlot)
```

Indeks Fowlkesa-Mallowsa zachowuje się bardzo podobnie do indeksu Jaccarda. 
Ma taką samą przewagę nad indeksem Randa. 

# Wewnętrzne

W tej części opiszę zachowanie miar wewnętrznych dla naszych zbiorów, czyli tych, które nie korzystają z oznakowania klas. Te miary mają potencjalnie większe zastosowanie. 

## Gamma

Gamma - im wyższa, tym lepiej. Oto jak przedstawiają się wartości Gammy dla 
naszych zbiorów:

```{r, echo = FALSE}
plot(gammaPlot)
```

Miara gamma przewiduje o wiele gorzej optymalne wartości k, co było do przewidzenia, skoro nie korzysta z etykiet danych a priori. Jednak nadal daje całkiem dobre wyniki. Wyjątkiem jest na pewno wykres górny po prawej (spirale). Tak jak miary zewnętrzne pokazywały, że hclust2 jest zdecydowanie lepszy, tutaj odwrotnie. 

## Indeks Daviesa-Bouldin

Przyjmuje wartości z zakresu $[0, \infty]$ i jest miarą wewnętrznej wariancji klastrów. Oto jak przedstawiają się wartości indeksu Daviesa-Bouldina dla naszych zbiorów:

```{r, echo = FALSE}
plot(davbPlot)
```

Tym razem wartości mniejsze są lepszymi. Indeks dość dobrze przewiduje liczbę klastrów, chociaż nie poradził sobie ze spiralą. (Tutaj początkowa wartość dla jednego klastra wynosi zero. Oczywiście pojedynczy klaster nas nie interesuje.)

## Indeks Dunna

Im wyższy, tym lepsze klastrowanie. Oto jak przedstawiają się wyniki:

```{r, echo = FALSE}
plot(dunnPlot)
```

Ten wskaźnik dobrze poradził sobie ze spiralą, wskazując liczbę 3 jako najlepsze k. Na wykresie dolnym po prawej widać nagły skok wyniku dla k = 8. 
Zapewne siedem księżyców zostało własnymi klastrami, a pozostałe skupiska w 
środku ostatnim. Sprawdźmy:




```{r, echo = FALSE}
ggplot(d8, aes(x = x, y = y, color = as.factor(l8_k[[8]]))) +
          geom_point() + 
          theme_bw() + 
          theme(legend.position = 'none',
                axis.title = element_blank(),
                axis.text = element_blank(),
                axis.ticks = element_blank())
```

Rzeczywiście tak się stało. My wiemy, że klas jest więcej, ale i tak jest to bardzo dobry podział. 

Na innych zbiorach indeks Dunna nie zadziałał tak dobrze.

# Podsumowanie 

Z przedstawionego testu wiemy, że omówione wskaźniki różnie działają na różnych zbiorach. Indeks Dunna sprawdził się dobrze dla nieliniowych klastrów, ale zadziałał nie najlepiej na innych zbiorach. Do przedstawionych wskaźników należy się odnosić z umiarkowanym zaufaniem.

